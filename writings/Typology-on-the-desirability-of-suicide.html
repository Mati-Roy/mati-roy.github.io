<!DOCTYPE html>
<html>
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131917224-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'UA-131917224-1');
    </script>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>Mati Roy</title>
    <meta name="description" content="The personal website of Mati Roy."/>
    
    
       
    <!-- OGP tags -->    
    <meta property="og:title" content="A typology of the (un)desirability of (not) helping/blocking suicidal people"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://matiroy.com/writings/Typology-on-the-desirability-of-suicide.html"/>
    <meta property="og:image" content="https://matiroy.com/images/profile_transparent_crop.png"/>
    <meta property="og:site_name" content="Mati Roy's website"/>
    <meta property="og:description" content="
    Note on content: This piece is NOT about the long term civilisational impact of various policies on suicide, but rather on the (direct) impact that actions and policies would have on suicidal people themselves.
    Note on approach to reading: I suggest contemplating the possible extremes of each aspect; I will sometimes provide them.
    "/>


  </head>
  <body>

    <nav><a href="../index.html">Home</a> | <a href="../writings.html">Writings</a> | <a href="../contact.html">Contact</a></nav>
    

<!----- Conversion time: 0.94 seconds.


Using this HTML file:

1. Cut and paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β17
* Sun Apr 14 2019 14:29:10 GMT-0700 (PDT)
* Source doc: https://docs.google.com/open?id=1mReidVBNVMVug3q2ppUiKbpFcLMvESuuC0qENqJTCKQ
----->


<p>
<strong><a href="https://docs.google.com/document/d/1mReidVBNVMVug3q2ppUiKbpFcLMvESuuC0qENqJTCKQ/">Google Doc</a> </strong>| <strong>Author</strong>: Mati Roy | <strong>Created</strong>: 2019-04-14 | <strong>Updated</strong>: 2019-04-14 | <strong>Published</strong>: 2019-04-14 | <strong>Status</strong>: looking for feedback | <strong>Feedback</strong>: welcome; especially suggestions for other considerations
</p>
<p>
<strong>Epistemic status</strong>: This piece is merely attempting to map the answer space, and not making any attempts to answer the proposed questions. It seems like a good starting point, but I expect other relevant features to come up when I share this with other people. Putting a feature as part of the map doesn’t imply that this feature is important (to me) necessarily, but rather that it might be an aspect at least some people would take into consideration.
</p>
<h1>A typology of the (un)desirability of (not) helping/blocking suicidal people</h1>


<p>
<strong>Note on content</strong>: This piece is NOT about the long term civilisational impact of various policies on suicide, but rather on the (direct) impact that actions and policies would have on suicidal people themselves.
</p>
<p>
<strong>Note on approach to reading</strong>: I suggest contemplating the possible extremes of each aspect; I will sometimes provide them.
</p>
<h2>Value related questions</h2>


<p>
<strong>How <span class="color1">sure</span> do you need to be that <span class="color2">someone</span> <span class="color3">wants</span> to <span class="color4">die</span> to <span class="color5">let them die?</span></strong>
</p>
<p>
Variations on the aspect of <strong class="color1">probability</strong>:
</p>
<ul>
<li>credence on an individual 
<ul>

<li><strong>Extremes</strong>: Only let someone die if you’re 100% they want to die — let someone die as soon as you’re not 100% they want to live.
</li> 
</ul>

<li>frequency on a population 
<ul>
 
<li><strong>Details</strong>: Say you had the choice among various policies, with different ratio of letting people commit suicide involuntarily to letting people live involuntarily
 
<li><strong>Extremes</strong>: Don’t let one person die involuntarily no matter how many people it would cause to live involuntarily — Don’t let one person live involuntarily no matter how many people it would cause to die involuntarily
</ul>
</ul>
<p>
Variations on the aspect of the <strong class="color2">person</strong>: 
</p>

<ul>

<li>someone that can’t communicate their preferences (ex.: some non-human animals)

<li>the amount of life lost 
<ul>
 
<li><strong>Extremes</strong>: someone that would be expected to die soon from another cause VS someone that is expected to be able to eventually reach an Utopic world
</li> 
</ul>

<li>someone that said they wanted to die or someone that is attempting suicide (as separated from our credence that they want to die)
</li>
</ul>
<p>
On minds as multiple people:
</p>
<ul>

<li>What if someone had said they wanted to be prevented from committing suicide in the past?

<li>Are people multi-agent systems, so that different parts of the mind might be in control at different time, and that one part of the mind might take an unilateral catastrophic decision for the other parts of the mind?

<li>Do people have a moral obligation to their future selves (ex.: if their future selves want to live)? 
<ul>
 
<li>What if someone is expected to acquire a better model of their preferences soon (ie. some people would argue kids fit that description; people under the influence of some drugs might also fit that description)

</ul></ul>
<p>
Variations on the aspect of their <strong class="color3">motivation</strong>: 
</p>

<p>
One the nature of the motivation:
</p>
<ul>

<li>egoistic (ex.: stop suffering)

<li>tribalistic (ex.: get revenge, prove a point)

<li>altruistic (ex.: reduce medical expenses)
</li>
</ul>
<p>
On the accuracy of the motivation:
</p>
<ul>

<li>someone that is (not) committing suicide because of an error in their model of the world about the impact their suicide will have (ex.: if a net positive person thought “society” would be better without them; or if someone wrongly thought their future would contain a lot of suffering)

<li>someone is killing themselves without (fully) knowing it
</ul>
</ul>
<p>
Variations on the aspect of <strong class="color4">dying</strong>: 
</p>
<ul>

<li>increasing their probability of dying

<li>reducing their lifespan

<li>erasing their identity
</li>
</ul>
<p>
Variations on the aspect of <strong class="color5">facilitating their death</strong>:
</p>
<ul>

<li>(not) kill them

<li>(not) assist their suicide

<li>remove/add life support

<li>(not) resuscitate them

<li>(not) preserve them

<li>add/remove suicidal devices 
<ul>
 
<li><strong>Extremes</strong>: give everyone a custom pill that can kill them instantaneously (but not other people) — have absolutely no objects / substances / hard surfaces accessible
</li> 
</ul>

<li>(not) help them come up with ways to commit suicide

<li>(not) physically stop them
</li>
</ul>
<h2>Epistemic related questions</h2>


<p>
How many people would like to die, but are not able to?
</p>
<p>
How many people (would) change their mind after attempting suicide? (or otherwise don’t really want to die in some ways).
</p>

    <link rel="stylesheet" href="../style.css">

  </body>
</html>

